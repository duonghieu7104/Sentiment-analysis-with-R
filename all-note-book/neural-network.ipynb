{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.6.0","file_extension":".r","codemirror_mode":"r"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":205223647,"sourceType":"kernelVersion"}],"dockerImageVersionId":30751,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"install.packages(\"keras\")\ninstall.packages(\"tensorflow\")\ninstall.packages(\"caret\")","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load required libraries\nlibrary(keras)\nlibrary(tidyverse)\nlibrary(caret)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the CSV file\ndata <- read.csv(\"/kaggle/input/create-embedding-word2vec-from-ggnewsvector/data_with_embeddings.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_embedding <- function(embedding_str) {\n  tryCatch({\n    nums <- str_extract_all(embedding_str, \"-?\\\\d+\\\\.\\\\d+e?-?\\\\d*\")[[1]]\n    if(length(nums) == 300) {\n      return(as.numeric(nums))\n    } else {\n      return(NULL)\n    }\n  }, error = function(e) {\n    return(NULL)\n  })\n}\n\nembeddings_list <- lapply(data$embedding, process_embedding)\n\nvalid_indices <- which(!sapply(embeddings_list, is.null))\nprint(paste(\"Number of valid embeddings:\", length(valid_indices)))\n\nembeddings_matrix <- do.call(rbind, embeddings_list[valid_indices])\nlabels <- to_categorical(data$label[valid_indices], num_classes = 6)\n\n# In thông tin sau khi lọc\nprint(paste(\"Final embeddings matrix dimension:\", paste(dim(embeddings_matrix), collapse = \" x \")))\nprint(paste(\"Final labels dimension:\", paste(dim(labels), collapse = \" x \")))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set.seed(123)\ntrain_indices <- createDataPartition(y = valid_indices, p = 0.9, list = FALSE)\n\nX_train <- embeddings_matrix[train_indices,]\nX_test <- embeddings_matrix[-train_indices,]\ny_train <- labels[train_indices,]\ny_test <- labels[-train_indices,]\n\n# In kích thước của tập train/test\nprint(\"Training set dimensions:\")\nprint(dim(X_train))\nprint(dim(y_train))\nprint(\"Test set dimensions:\")\nprint(dim(X_test))\nprint(dim(y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_df <- as.data.frame(X_train)\nX_test_df <- as.data.frame(X_test)\n\nX_train_df$label <- apply(y_train, 1, function(x) which(x == 1) - 1)\nX_test_df$label <- apply(y_test, 1, function(x) which(x == 1) - 1)\n\n# Save as CSV files\nwrite.csv(X_train_df, \"train_data.csv\", row.names = FALSE)\nwrite.csv(X_test_df, \"test_data.csv\", row.names = FALSE)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data <- read.csv(\"train_data.csv\")\ntest_data <- read.csv(\"test_data.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train <- as.matrix(train_data[, -ncol(train_data)])\ny_train <- to_categorical(train_data$label, num_classes = 6)\n\nX_test <- as.matrix(test_data[, -ncol(test_data)])\ny_test <- to_categorical(test_data$label, num_classes = 6)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model <- keras_model_sequential() %>%\n  layer_dense(units = 256, activation = \"relu\", input_shape = c(300)) %>%\n  layer_dropout(rate = 0.2) %>%\n  layer_dense(units = 128, activation = \"relu\") %>%\n  layer_dropout(rate = 0.2) %>%\n  layer_dense(units = 64, activation = \"relu\") %>%\n  layer_dropout(rate = 0.1) %>%\n  layer_dense(units = 6, activation = \"softmax\")\n\n# Compile\nmodel %>% compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_adam(learning_rate = 0.001),\n  metrics = c(\"accuracy\")\n)\n\n# Early Stopping\nearly_stopping <- callback_early_stopping(\n  monitor = \"val_loss\", \n  patience = 15,\n  restore_best_weights = TRUE\n)\n\n# Training\nhistory <- model %>% fit(\n  X_train, y_train,\n  epochs = 250,\n  batch_size = 64,\n  validation_split = 0.2,\n  callbacks = list(early_stopping)\n)\n\n# Evaluate\nresults <- model %>% evaluate(X_test, y_test)\nprint(results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nsave_model_hdf5(model, \"sentiment_model.h5\")","metadata":{},"execution_count":null,"outputs":[]}]}